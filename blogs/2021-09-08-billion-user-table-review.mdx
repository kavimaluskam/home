---
title: The Billion User Table - Decentralization of Data taking place
date: "2021-09-09"
hero: /blogs/2021-09-08-billion-user-table-review/hero.jpeg
heroName: Davide Ragusa
heroUrl: https://unsplash.com/@davideragusa
excerpt: >
  Review on The Billion User Table on 1729.com,
  a hypothesis on future data decentralization.
tags:
  - 1729.com
  - decentralization
---

This article is a review on the
post [The Billion User Table](https://1729.com/the-billion-user-table)
by [Jon Stokes](https://twitter.com/jonst0kes) @ [1729.com](https://1729.com).

[1729.com](https://1729.com) is a project
by [Balaji Srinivasan](https://twitter.com/balajis),
which is a newsletter and a community that pays subscribers
with tasks, tutorials, interaction about
cryptocurrency, DeFi, and DAO. Go check the details in
[A Newsletter that pays you](https://1729.com/a-newsletter-that-pays-you).

## The current data economy and monopoly

Before explaining Jon's proposal on the giant user table, let's have
a quick review on the existing internet / SaaS world.

Looking into some big names of the current internet / SaaS world, we can tell
they have all been following the below rules of monetization:

1. Launching an application

2. Focusing on growth and new users, with better service and UX

3. Monetizing its user base and data, with personalized ADs and data sales

The bad thing here is, this put us in a situation that most of the tech giants,
or the whole internet is flooding with ADs, growth and click-rate oriented
contents, and exploitation of user's data without users' consent.

<div class="Image__Small">
  <img
    src="./images/mark-zuckerberg-and-im-sorry.gif"
    alt="its not only your fault"
  />
  <figcaption>It's OK, it's not only your fault.</figcaption>
</div>

Moreover it's vicious cycle, due to the
[Network Effect / Metcalfe's Law](https://www.peterfisk.com/2020/02/metcalfes-law-explains-how-the-value-of-networks-grow-exponentially-there-are-5-types-of-network-effects/#:~:text=%E2%80%9CMetcalfe's%20Law%E2%80%9D%20says%20that%20a,computers%2C%20servers%20and%20simply%20users.&text=As%20it%20becomes%20less%20and,become%20extremely%20valuable%20over%20time.).

> "The most critical thing your users table does for you, though,
> is it gives you access to network effects, and these network effects
> give you some lock-in. The more users your platform has,
> the more value it has to any one user (cf. Metcalfe's law),
> and the more value it has to any one user, then A) the easier it is
> to attract new users, and B) the harder it is for any one user to leave
> (because to leave is to give up all that value)."

With a tremendous user base, an application just become inevitable for users
looking for service in that domain, and they data monopoly continues.

## A Single Billion User Table

Proposed by Jon that with the infrastructure of blockchain,
and decentralized application, the applications can have their database,
especially user data saved in blockchain.

> "The public blockchain amounts to a single, massive users table for the
> entire Internet, and the next wave of distributed applications will be
> built on top of it. This has all kinds of market and political implications
> that I'm just now starting to get my head around."

And this can bring an evolution to the currency data economics,
as Jon proposed.

With a community of applications shared their user data on blockchain,
the applications' user data are fairly open, and they may have a much rich
user profile with user behaviors and history across different domains.

It will be like a global single-sign-on on blockchain. Applications which
put their user data on chain will be in the party of blockchain-identities
and share a same billion user table. The network effect will no longer be
monopolized by the tech giants and their own userbases, while the standalone
billion user table stands up and challenge them. And this kind of shifting
of power is what blockchain meant to do, decentralization.

## How a Single Table may work

Technically, this can be down by technologies like
[IPFS](https://hackernoon.com/a-beginners-guide-to-ipfs-20673fedd3f)
and Web3 databases.

Despite the fact that handling data on-chain would be
expensive, applications may decide to put the large data / files
off-chain while the real transactions on-chain.
And with the development on on-chain data exploring technologies,
like [The Graph](https://thegraph.com/blog/the-graph-grt-token-economics),
the cost would be cheaper and more user-friendly.

And, as the DAO community keep growing, I'd love to see more crypto-based
**single sign-on service**, or even **SDK** provided for
better engineering experience. Imagine some open source crypto based Firebase
launch, it would greatly draw more new applications to integrate and join the
single-million-table idea. With the decentralized nature, profits for such
SDK service would no longer be monopolized by the provider only, but shared
across the whole community.

## Impact to data industry

It is also interesting to think about this proposal from the data engineering
point of view.

In the current data market, data are owned by individual tech giants, which
all owned armies of data engineering and data science to organize and build on
their own data, so to create more personalized ADs, recommendation, service,
etc.

With the shifting of data to blockchain, data would be saved on chain publicly.
Data source will no longer be a problem of data-oriented companies organization.

This may also bring new dynamic to the data industry, wheres
**decentralization of data** happens. With the ability to process
and research on the large amount of data, anyone can pay the same cost
to explore the on-chain data and develop insights or user-based functionality.
Start ups or small-scaled companies may use the gigantic existing domain data
to build their own feature or solve some cold start problems.

And, on chain data query would be gaining in importance on data engineering.

## Difficulties to the fantasy table

Yet the road to this is not straight forward.

First of all, we have to think of the **on-chain data quality**.
Important metrics like engagement in linkedin platform Jon proposed,
or common ones like follower numbers, popularity, or even content based metrics,
are very likely not born in the user table in the very first day.

User profile related metrics can be blent into the user table,
only after numbers of data pipelines and analytic tools,
especially for data of giant scales. Putting these data in
a decentralized way simply means sharing the companies' internal metric data
to the chain, which is not very intuitive nor incentive. On the other hand,
putting all raw metrics on-chain would be relatively expensive, and for the
extraction and analyze part? cost would go up in scales.

<div class="Image__Small">
  <img src="./images/DAG.png" alt="airbnb-dag" />
  <figcaption>
    An example DAG from{" "}
    <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70">
      Airbnb blog post
    </a>
    , so which portion of data should we put on chain?
  </figcaption>
</div>

Besides, in the current stage, data IO on chain is still costly and slow,
compared to traditional internet technologies.

We are still waiting for improvement on on-chain data IO technologies to meet
the above issues.

## What DAOs really bring

So summing up, Jon's proposal on a billion user table is very insightful to me,
despite of the time it may takes and in what form it would take place.
But most importantly:

- This brings us the decentralization of data currently monopolized by tech
  giants

- Blockchain / decentralized Single Sign-On / SDK would be a way to the future

- How Data / Data Engineering industry would be impacted

And what DAOs / Web3 would bring is far beyond.
An insightful article is here fo your interest:
[What is Web3](https://www-freecodecamp-org.cdn.ampproject.org/c/s/www.freecodecamp.org/news/what-is-web3/amp/).

So this is it for now, Cheers guys üçª.
